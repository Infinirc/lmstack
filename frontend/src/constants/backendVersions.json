{
  "vllm": {
    "description": "vLLM - High-throughput LLM inference engine",
    "versions": [
      {
        "version": "latest",
        "image": "vllm/vllm-openai:latest",
        "recommended": true
      },
      { "version": "v0.13.0", "image": "vllm/vllm-openai:v0.13.0" },
      { "version": "v0.12.0", "image": "vllm/vllm-openai:v0.12.0" },
      { "version": "v0.11.2", "image": "vllm/vllm-openai:v0.11.2" },
      { "version": "v0.11.1", "image": "vllm/vllm-openai:v0.11.1" },
      { "version": "v0.11.0", "image": "vllm/vllm-openai:v0.11.0" },
      { "version": "v0.10.2", "image": "vllm/vllm-openai:v0.10.2" },
      { "version": "v0.10.1.1", "image": "vllm/vllm-openai:v0.10.1.1" },
      { "version": "v0.10.1", "image": "vllm/vllm-openai:v0.10.1" },
      { "version": "v0.10.0", "image": "vllm/vllm-openai:v0.10.0" },
      { "version": "v0.9.2", "image": "vllm/vllm-openai:v0.9.2" },
      { "version": "v0.9.1", "image": "vllm/vllm-openai:v0.9.1" },
      { "version": "v0.9.0.1", "image": "vllm/vllm-openai:v0.9.0.1" },
      { "version": "v0.9.0", "image": "vllm/vllm-openai:v0.9.0" },
      { "version": "v0.8.5.post1", "image": "vllm/vllm-openai:v0.8.5.post1" },
      { "version": "v0.8.5", "image": "vllm/vllm-openai:v0.8.5" },
      { "version": "v0.8.4", "image": "vllm/vllm-openai:v0.8.4" },
      { "version": "v0.8.3", "image": "vllm/vllm-openai:v0.8.3" },
      { "version": "v0.8.2", "image": "vllm/vllm-openai:v0.8.2" },
      { "version": "v0.6.6.post1", "image": "vllm/vllm-openai:v0.6.6.post1" },
      { "version": "v0.6.6", "image": "vllm/vllm-openai:v0.6.6" },
      { "version": "v0.6.5", "image": "vllm/vllm-openai:v0.6.5" },
      { "version": "v0.6.4.post1", "image": "vllm/vllm-openai:v0.6.4.post1" },
      { "version": "v0.6.4", "image": "vllm/vllm-openai:v0.6.4" },
      { "version": "v0.6.3.post1", "image": "vllm/vllm-openai:v0.6.3.post1" },
      { "version": "v0.6.3", "image": "vllm/vllm-openai:v0.6.3" },
      { "version": "v0.6.2", "image": "vllm/vllm-openai:v0.6.2" },
      { "version": "v0.6.0", "image": "vllm/vllm-openai:v0.6.0" },
      { "version": "v0.5.5", "image": "vllm/vllm-openai:v0.5.5" },
      { "version": "v0.5.4", "image": "vllm/vllm-openai:v0.5.4" }
    ]
  },
  "sglang": {
    "description": "SGLang - Fast serving framework for LLMs",
    "versions": [
      {
        "version": "latest",
        "image": "lmsysorg/sglang:latest",
        "recommended": true
      },
      { "version": "v0.5.7", "image": "lmsysorg/sglang:v0.5.7" },
      { "version": "v0.5.6.post2", "image": "lmsysorg/sglang:v0.5.6.post2" },
      { "version": "v0.5.6.post1", "image": "lmsysorg/sglang:v0.5.6.post1" },
      { "version": "v0.5.6", "image": "lmsysorg/sglang:v0.5.6" },
      { "version": "v0.5.5.post3", "image": "lmsysorg/sglang:v0.5.5.post3" },
      { "version": "v0.5.5.post2", "image": "lmsysorg/sglang:v0.5.5.post2" },
      { "version": "v0.5.5.post1", "image": "lmsysorg/sglang:v0.5.5.post1" },
      { "version": "v0.5.5", "image": "lmsysorg/sglang:v0.5.5" },
      { "version": "v0.5.4", "image": "lmsysorg/sglang:v0.5.4" },
      { "version": "v0.5.3", "image": "lmsysorg/sglang:v0.5.3" },
      { "version": "v0.5.2", "image": "lmsysorg/sglang:v0.5.2" },
      { "version": "v0.5.1", "image": "lmsysorg/sglang:v0.5.1" },
      { "version": "v0.5.0", "image": "lmsysorg/sglang:v0.5.0" },
      { "version": "v0.4.3.post2", "image": "lmsysorg/sglang:v0.4.3.post2" },
      { "version": "v0.4.3.post1", "image": "lmsysorg/sglang:v0.4.3.post1" },
      { "version": "v0.4.3", "image": "lmsysorg/sglang:v0.4.3" },
      { "version": "v0.4.2", "image": "lmsysorg/sglang:v0.4.2" },
      { "version": "v0.4.1", "image": "lmsysorg/sglang:v0.4.1" },
      { "version": "v0.4.0", "image": "lmsysorg/sglang:v0.4.0" },
      { "version": "v0.3.6", "image": "lmsysorg/sglang:v0.3.6" },
      { "version": "v0.3.5.post2", "image": "lmsysorg/sglang:v0.3.5.post2" },
      { "version": "v0.3.5", "image": "lmsysorg/sglang:v0.3.5" }
    ]
  },
  "ollama": {
    "description": "Ollama - Run LLMs locally",
    "versions": [
      {
        "version": "latest",
        "image": "ollama/ollama:latest",
        "recommended": true
      },
      { "version": "0.13.5", "image": "ollama/ollama:0.13.5" },
      { "version": "0.13.4", "image": "ollama/ollama:0.13.4" },
      { "version": "0.13.3", "image": "ollama/ollama:0.13.3" },
      { "version": "0.13.2", "image": "ollama/ollama:0.13.2" },
      { "version": "0.13.1", "image": "ollama/ollama:0.13.1" },
      { "version": "0.13.0", "image": "ollama/ollama:0.13.0" },
      { "version": "0.12.11", "image": "ollama/ollama:0.12.11" },
      { "version": "0.12.10", "image": "ollama/ollama:0.12.10" },
      { "version": "0.12.9", "image": "ollama/ollama:0.12.9" },
      { "version": "0.12.8", "image": "ollama/ollama:0.12.8" },
      { "version": "0.12.7", "image": "ollama/ollama:0.12.7" },
      { "version": "0.12.6", "image": "ollama/ollama:0.12.6" },
      { "version": "0.12.5", "image": "ollama/ollama:0.12.5" },
      { "version": "0.12.4", "image": "ollama/ollama:0.12.4" },
      { "version": "0.12.3", "image": "ollama/ollama:0.12.3" },
      { "version": "0.12.2", "image": "ollama/ollama:0.12.2" },
      { "version": "0.12.1", "image": "ollama/ollama:0.12.1" },
      { "version": "0.12.0", "image": "ollama/ollama:0.12.0" },
      { "version": "0.11.0", "image": "ollama/ollama:0.11.0" },
      { "version": "0.10.0", "image": "ollama/ollama:0.10.0" },
      { "version": "0.9.0", "image": "ollama/ollama:0.9.0" },
      { "version": "0.8.0", "image": "ollama/ollama:0.8.0" },
      { "version": "0.7.0", "image": "ollama/ollama:0.7.0" },
      { "version": "0.6.0", "image": "ollama/ollama:0.6.0" },
      { "version": "0.5.7", "image": "ollama/ollama:0.5.7" },
      { "version": "0.5.4", "image": "ollama/ollama:0.5.4" }
    ]
  }
}
